{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "import setup\n",
    "\n",
    "setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit.models import RedditPost\n",
    "from snapshots.models import BrightDataSnapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIGHT_DATA_API_KEY = os.environ.get(\"BRIGHT_DATA_API_KEY\")\n",
    "\n",
    "assert BRIGHT_DATA_API_KEY is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crawl_headers():\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {BRIGHT_DATA_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_scrape_snapshot(subreddit_url: str, num_of_posts: int = 20) -> str:\n",
    "    url = \"https://api.brightdata.com/datasets/v3/trigger?dataset_id=gd_lvz8ah06191smkebj4&notify=false&include_errors=true&type=discover_new&discover_by=subreddit_url&limit_per_input=100\"\n",
    "    headers = get_crawl_headers()\n",
    "    dataset_id = \"gd_lvz8ah06191smkebj4\"\n",
    "    data = json.dumps(\n",
    "        {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"url\": f\"{subreddit_url}\",\n",
    "                    \"sort_by\": \"Top\",\n",
    "                    \"sort_by_time\": \"Today\",\n",
    "                    \"num_of_posts\": num_of_posts,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = requests.post(url=url, headers=headers, data=data)\n",
    "\n",
    "    response.raise_for_status()\n",
    "\n",
    "    scrape_data = response.json()\n",
    "    snapshot_id = scrape_data.get(\"snapshot_id\")\n",
    "\n",
    "    BrightDataSnapshot.objects.create(\n",
    "        snapshot_id=snapshot_id,\n",
    "        dataset_id=dataset_id,\n",
    "        status=\"Unknown\",\n",
    "    )\n",
    "\n",
    "    return scrape_data.get(\"snapshot_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_snapshot_result = perform_scrape_snapshot(\"https://www.reddit.com/r/django\")\n",
    "\n",
    "print(scrape_snapshot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot_progress(snapshot_id: str) -> bool | None:\n",
    "    url = f\"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}\"\n",
    "    headers = get_crawl_headers()\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url=url, headers=headers)\n",
    "\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        snapshot_id = result.get(\"snapshot_id\")\n",
    "        dataset_id = result.get(\"dataset_id\")\n",
    "\n",
    "        BrightDataSnapshot.objects.update_or_create(\n",
    "            snapshot_id=snapshot_id,\n",
    "            dataset_id=dataset_id,\n",
    "            defaults={\n",
    "                \"status\": result.get(\"status\"),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return result.get(\"status\") == \"ready\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_snapshot_progress(scrape_snapshot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_snapshot(snapshot_id: str) -> dict[str, str] | None:\n",
    "    url = f\"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}\"\n",
    "    headers = get_crawl_headers()\n",
    "    params = {\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url=url, headers=headers, params=params)\n",
    "\n",
    "        response.raise_for_status()\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_results = download_snapshot(scrape_snapshot_result)\n",
    "\n",
    "print(reddit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_field_names = [field.name for field in RedditPost._meta.get_fields()]\n",
    "\n",
    "print(model_field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_fields = [\"id\", \"post_id\", \"url\"]\n",
    "valid_fields = [x for x in model_field_names if x not in skip_fields]\n",
    "\n",
    "print(valid_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in reddit_results:\n",
    "    post_id = thread.get(\"post_id\")\n",
    "    url = thread.get(\"url\")\n",
    "    update_data = {k: v for k, v in thread.items() if k in valid_fields}\n",
    "\n",
    "    print(post_id, url, update_data)\n",
    "\n",
    "    RedditPost.objects.update_or_create(\n",
    "        post_id=post_id,\n",
    "        url=url,\n",
    "        defaults=update_data,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
